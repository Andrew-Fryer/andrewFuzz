# TODO: use inheritence to yet rid of the icky duplcate methods
# TODO: implement some nice clone methods so that I don't have to pass tons of crap into constructors in parse and fuzz methods
# rename `fuzz` to `get_mutations`?
# TODO: make contexts work so that 'dynamic' data models are useful

Note: I'm assuming that performance is a secondary issue because the SUT will consume the bulk of all resources anyway...


Hey, let's think about this for a second...
A grammar does not store data and is an un-restricted, directed graph.
An AST stores data and is a tree.



Another thought:
I think we need to do stuff a certain way:
-I think that fuzzing should return an object tree
-I think that all objects in trees should be immutable
-everything in the tree needs to be clonable
This way, we can clone the tree and then replace sub-trees (usually leaves) as we please.
I'll need a mechanism to make replacing subtrees manageable.
This could be:
-something complex (like storing the tree structure in another structure as well <- like a dict that maps paths to sub-trees)
    -> this will inevitably lead to some management overhead and having to manage this structure in places that will be awkward
-traverse the tree checking with the == operator to detect the node we want to replace
    -> slow
    -> when we change a sub-tree from one constraint, we need to update all other references into that sub-tree
-The parent class of all Non-terminals has a system that finds a sub-tree from a "path" (list of strings which we index on the obj.__dict__ thing...)
I'm currently leaning towards the last option.

Seperate initialization from memory allocation (for creating an object in the tree). This way we don't need weird hoisting stuff!
^actually, we only need to do that for setting the children on a branching non-terminal.

When I extend this codebase to fuzz systems with multiple packets of communication (state), I can just have a state object that is referenced by the fuzz and parse methods.
I have a decsion to make here...
I can pipe a state object through all of the parsing and fuzzing.
It may be possible to do this smoothly using monads...
Or,
I can just have a reference to a state object in the grammar (closure style) and then set up the state before parsing or fuzzing a stage of a protocol...

Is there any legitimate reason that code in the grammar should mutate the state?
-within the same request we should be using constraints!
-remember a mutated value (handle, challenge, etc) so that it matches across requests
    -> I think it is reasonable to write glue code that pulls values out of the tree and stuffs them into the state for the next stage
Anything dependent on the fuzz is tied to that fuzz :|
    -> this means one global object won't work if the grammar can mutate it
For now, I'm deciding to disallow the grammar from mutating state.

A whole seperate problem is determining which responses from the System Under Test are "interesting".
We can think of this as being a binary deal, where we test the output in some well-defined way.
(Is the response the same as the response for the un-fuzzed case except for some timestamps and stuff?
Is the response an error when we broke something? <- that means that the fuzzing system will need to indicate which inputs break the grammar and which don't...)
Or, we can think of interesting-ness as a real value which can be composed from a metric and/or ML approaches.
The features should include:
-it is an error or an acutal response
-what is the error code/type (the error code might indicate syntactic vs. semantic...)
-how long is the response (will hopefully find heartbleed)
-how long did it take to respond? -> AndrewFuzz could re-run interesting test to get more insight on this...
-features of the input data -> my thinking here is that we expect similar inputs to yield similar outputs
Then, a clusting algorithm should be able to identify interesting responses!
Note: in a multi-message system, it would probably make sense to try interesting first messages more than normal first messages...

I think I should make a `FuzzingProgress` class that is basically a tuple of (`DataModel`, `Fuzziness`), where `Fuzziness` is an enum that describes what level the fuzz is supposed to test (Correct, SemanticError, SyntacticError, Both, or Unknown).
^Or, I could make the DataModel class have a `self.fuzziness` property which is set by the constructor/set_children method.
^I think that the tree of fuzziness values could be a really good feature for clustering the error messages received...
    This feature vector could be as simple as: (#Correct, #Semantic, #Syntactic, #Both, #Unknown) where each count is of the nodes in the tree that both have that Fuzziness and are different from the un-fuzzed value.


I think it might be a good idea to monadify the ParsingProgress and FuzzingProgress classes.
The classes now store the list/generator of (DataModel, remaining_stream/Fuzziness) tuples.
The classes have a higher-order function!
`map` (or something) 
Wait, I think this is just the list monad from Haskell...

^The parsing mechanism needs to propagate a generator of (DataModel, Stream, readonly_state)
parse :: Stream -> State -> [(DataModel, Stream)]
We can think of the parse method as somehting that eats input. On the side, it produces a DataModel instance.
The flatten function is basically `itertools.chain` for Union and `itertools.product` for Sequence, but then we have to combine the list of children data models into a Sequence or Set or whatever...
I think it is actually cleaner just to keep that code in the parse methods of the NonTerminal classes (at least for now).
