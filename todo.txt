# TODO: use inheritence to yet rid of the icky duplcate methods
# TODO: implement some nice clone methods so that I don't have to pass tons of crap into constructors in parse and fuzz methods
# rename `fuzz` to `get_mutations`?
# TODO: make contexts work so that 'dynamic' data models are useful

Note: I'm assuming that performance is a secondary issue because the SUT will consume the bulk of all resources anyway...


Hey, let's think about this for a second...
A grammar does not store data and is an un-restricted, directed graph.
An AST stores data and is a tree.



Another thought:
I think we need to do stuff a certain way:
-I think that fuzzing should return an object tree
-I think that all objects in trees should be immutable
-everything in the tree needs to be clonable
This way, we can clone the tree and then replace sub-trees (usually leaves) as we please.
I'll need a mechanism to make replacing subtrees manageable.
This could be:
-something complex (like storing the tree structure in another structure as well <- like a dict that maps paths to sub-trees)
    -> this will inevitably lead to some management overhead and having to manage this structure in places that will be awkward
-traverse the tree checking with the == operator to detect the node we want to replace
    -> slow
    -> when we change a sub-tree from one constraint, we need to update all other references into that sub-tree
-The parent class of all Non-terminals has a system that finds a sub-tree from a "path" (list of strings which we index on the obj.__dict__ thing...)
I'm currently leaning towards the last option.

Seperate initialization from memory allocation (for creating an object in the tree). This way we don't need weird hoisting stuff!
^actually, we only need to do that for setting the children on a branching non-terminal.

When I extend this codebase to fuzz systems with multiple packets of communication (state), I can just have a state object that is referenced by the fuzz and parse methods.
I have a decsion to make here...
I can pipe a state object through all of the parsing and fuzzing.
It may be possible to do this smoothly using monads...
Or,
I can just have a reference to a state object in the grammar (closure style) and then set up the state before parsing or fuzzing a stage of a protocol...

Is there any legitimate reason that code in the grammar should mutate the state?
-within the same request we should be using constraints!
-remember a mutated value (handle, challenge, etc) so that it matches across requests
    -> I think it is reasonable to write glue code that pulls values out of the tree and stuffs them into the state for the next stage
Anything dependent on the fuzz is tied to that fuzz :|
    -> this means one global object won't work if the grammar can mutate it
For now, I'm deciding to disallow the grammar from mutating state.

Is there any reason that contraints between packets are different form those within a packet?
It is feasible to swap state objects in between packets, but not during the fuzz of a single packet.
Also, we may want to re-order packets as part of our fuzzing.
Is it feasible to have a Session NonTerminal that takes care of all of this? (It would have packet grammars as its children.)

Hold on; I thought of another problem :|
Some SUTs won't be clonable. By that I mean that we can't serialize them at a stage in the protocol and duplicate them for each fuzz of the current stage.
Instead, we'll have to replay the interactions in the previous stages to create a SUT instance that is at the correct stage and has been fed the same fuzz in the previous interactions.
The issue here is that non-deterministic server responses will create differences in the session data for the session that created the fuzz and the session that the fuzz is being used in.
Therefore, session data needs to be injected into fuzz after we've had an opportunity to set up the session that we are fuzzing.
I can do pretty simply by only using session data during serialization (rather than fuzzing).
Unfortunately, this forces us to know the number of fuzzy instances will be produced by a DataModel before knowing the session data.
(The `fuzz` method can return instances that each know how they should fuzz differently once they are given the session data. This hurts me a bit on the inside, but they could then do compute the fuzz in the `serialize` method.)
Alternatively, I could do the previous fuzzy stages many times, fuzzing the current stage DataModel each time (with the current session data) and then using the first fuzz after filtering out fuzz that we've tried before. This requires saving previous fuzz and a fancy equality operation that should probably return true for any two timestamps etc... This will also be incredibly inefficient.
(Actually, the most pure way I can think of would be to repeatedly fuzz with session data and chose a fuzzy DataModel instance randomly.)
If we know that the same fuzz of the current stage's DataModel will be produced for each session then we can just use take the ith fuzz (because we know that the filter will simply remove the first i fuzzy DataModel instances). In this case, we can also avoid the work of creating the first i fuzzy DataModel instances if we do the approach I thought of and wrote down a few lines up (we inject the session data in the `serialize` method.)
The assumption I'd be making here is that "the fuzzing strategy is independent of non-determinism in the SUT's previous stages".
I should probably create a comprehensive list of the assumptions AndrewFuzz makes about the SUT.
-edge condition values of fields are known (and are in the fuzz methods of the primitives)
-

Another thing to consider:
It could be way too slow to create a new SUT instance for each peice of fuzz.
How can we fuzz effectively using the same instance?
How can I design AndrewFuzz to allow us to exploit optimizations around that?? (maybe I should think of them as being more central than optimizations even.)

A whole seperate problem is determining which responses from the System Under Test are "interesting".
We can think of this as being a binary deal, where we test the output in some well-defined way.
(Is the response the same as the response for the un-fuzzed case except for some timestamps and stuff?
Is the response an error when we broke something? <- that means that the fuzzing system will need to indicate which inputs break the grammar and which don't...)
Or, we can think of interesting-ness as a real value which can be composed from a metric and/or ML approaches.
The features should include:
-it is an error or an acutal response
-what is the error code/type (the error code might indicate syntactic vs. semantic...)
-how long is the response (will hopefully find heartbleed)
-how long did it take to respond? -> AndrewFuzz could re-run interesting test to get more insight on this...
-features of the input data -> my thinking here is that we expect similar inputs to yield similar outputs
Then, a clusting algorithm should be able to identify interesting responses!
Note: in a multi-message system, it would probably make sense to try interesting first messages more than normal first messages...

I think I should make a `FuzzingProgress` class that is basically a tuple of (`DataModel`, `Fuzziness`), where `Fuzziness` is an enum that describes what level the fuzz is supposed to test (Correct, SemanticError, SyntacticError, Both, or Unknown).
^Or, I could make the DataModel class have a `self.fuzziness` property which is set by the constructor/set_children method.
^I think that the tree of fuzziness values could be a really good feature for clustering the error messages received...
    This feature vector could be as simple as: (#Correct, #Semantic, #Syntactic, #Both, #Unknown) where each count is of the nodes in the tree that both have that Fuzziness and are different from the un-fuzzed value.


I think it might be a good idea to monadify the ParsingProgress and FuzzingProgress classes.
The classes now store the list/generator of (DataModel, remaining_stream/Fuzziness) tuples.
The classes have a higher-order function!
`map` (or something) 
Wait, I think this is just the list monad from Haskell...

^The parsing mechanism needs to propagate a generator of (DataModel, Stream, readonly_state)
parse :: Stream -> State -> [(DataModel, Stream)]
We can think of the parse method as somehting that eats input. On the side, it produces a DataModel instance.
The flatten function is basically `itertools.chain` for Union and `itertools.product` for Sequence, but then we have to combine the list of children data models into a Sequence or Set or whatever...
I think it is actually cleaner just to keep that code in the parse methods of the NonTerminal classes (at least for now).

Helpful snippets:
`bitarray(format(ord('a'), '08b')).tobytes().decode('ascii')`
`python -m unittest test_dir.dns`



I think I can rewrite a lot of inheritence a lot more nicely by having class properties like num_bits rather than passing that field around all the time, and the methods can all just use self.num_bits in their business...
I'm pretty sure propagate can just take a `contents` field, which is either `children` or `child` or `data` depending on what type of node it is...

I think I should have a chain of fuzzy objects back to the original!
    Actually, I could implement this in propagate pretty easily!
        I think the ideal is if parsing and fuzzing both uses `propagate`, but the link to the parent data model should have a label for how it was fuzzed or parsed...

I can also cache feature vectors in DataModel and remove them in propagate (but still cache the list of properties).
